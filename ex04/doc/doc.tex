\documentclass[a4paper,headings=small]{scrartcl}
\KOMAoptions{DIV=12}

\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{listings}

% define style of numbering
\numberwithin{equation}{section} % use separate numbering per section
\numberwithin{figure}{section}   % use separate numbering per section

% instead of using indents to denote a new paragraph, we add space before it
\setlength{\parindent}{0pt}
\setlength{\parskip}{10pt plus 1pt minus 1pt}

\title{Excercise 4 - \emph{Picture me naked}}
\subtitle{Computer Graphics I - WS12/13}
\author{\textbf{Team 6} (Rolf Schröder [340126], Robin Vobruba [343773])}
\date{\today}

\pdfinfo{%
  /Title    (Computer Graphics I - WS12/13 - Excercise 4 - Picture me naked)
  /Author   (Team 6: Rolf Schröder [340126], Robin Vobruba [343773])
  /Creator  ()
  /Producer ()
  /Subject  ()
  /Keywords ()
}

% Simple picture reference
%   Usage: \image{#1}{#2}{#3}
%     #1: file-name of the image
%     #2: percentual width (decimal)
%     #3: caption/description
%
%   Example:
%     \image{myPicture}{0.8}{My huge house}
%     See fig. \ref{fig:myPicture}.
\newcommand{\image}[3]{
	\begin{figure}[htbp]
		\centering
		\includegraphics[width=#2\textwidth]{#1}
		\caption{#3}
		\label{fig:#1}
	\end{figure}
}


\begin{document}

\maketitle

\subsection*{1. Abbildungsfehler}
Um das Dreieck mit einer Textur zu überziehen, muss jedem Pixel des Dreiecks ein Texel der Textur zugeordnet werden.
Wenn die Größe des Dreicks nicht mit der Größe der Textur übereinstimmt, kommt es zwangsläufig zu Abtastfehlern.
Bei einem Dreieck, das größer als die Textur ist, werden nebeneinander liegende Pixel häufig auf dasselbe Texel abgebildet (Pixel und Texel sind immer ganzzahlig).
So kann es passieren, dass ein Texel mehrere Male auf dem Dreieck gezeichnet wird (Oversampling).
Im umgekehrten Fall (Undersampling) ist die Textur wesentlich größer ("detailreicher") als das Dreieck.
Nun werden nicht alle Texel ausgelesen, weil das Dreieck nicht genügend Pixel hat.
Dadurch fehlen Teile der Textur auf dem gerenderten Dreieck.

\subsection*{2. MipMap}
Da eine Textur abhänig von der Entfernung zwischen Betrachter und texturiertem Objekt unterschiedlich detailreich ist, muss diese normalerweise gefiltert werden, um die gewünschte Detailtiefe zu ermitteln.
Eine MipMap enthält eine Textur in verschieden Auflösungen.
Somit ist es möglich, sehr schnell (ohne Berechnung) eine der vordefinierten Detailtiefen auszulesen.
Das wiederum ist sinnvoll für Echtzeitanwendungen, da die Berechnung eine obere Zeitschranke hat.
Eine MipMap bietet sich v.a. auch für Anwendungen an, in der texturierte Objekt häufig die Entfernung zu Beobachter wechseln (z.B. Ego-Shooter).
Dann muss diese nicht immer wieder neu gefiltert werden.

\subsection*{3. Zweischritt-Verfahren}
Surface tangents of the object have to vary less then $180^{\circ}$ in every dimension.
This is equivalent to the formulation:
There has to exist at least one point in space,
from to which we can connect a line to each point on the surface of the object,
and this line does not intersect the object in any other point.

\subsection*{4. Parametrisierung einer Environment Map}
Das kann man sich so vorstellen:
Wenn wir eine aus gleichseitigen, elastischen Dreiecken bestehende Kugel an einem Punkt aufschneiden,
und plat pressen,
so dass sie genau den Kreis einer EM Textur abdeckt,
dann werden die Dreiecke gegen aussen hin lang gezogen und in der höhe verringert.
Dadurch haben sie in einer Richtung eine höhere,
und in die dazu orthogonal liegende eine tiefere Pixel-Auflösung als die weiter innen liegenden Dreiecke,
bzw. als optimaler Weise ($\hat{=}$ in beiden Richtungen gleich).

% Wir generieren eine EM aus einer 3D Umgebung,
% bilden sie auf 2D ab,
% und platschen sie danach wieder auf ein 3D objekt.
% 3D $\rightarrow$ 2D $\rightarrow$ 3D;
% dabei geht natürlich Information verloren,
% was im Resultat sichtbar wird.

\subsection*{5. Projektives Texture Mapping}
Da die Bilder auf Objekte projiziert werden sollen, verhällt sich der imaginäre Projektor im Prinzip wie die "normale" Kamera aus der bei der Bildgenerierung.
Deshalb werden auf die Vertexe (des oder der Polygons/-e) ähnliche Transformationen angewendet.
Allerdings aus Sicht des Projektors.
Das bedeutet konkret, dass zunächst einmal die Vertexe (in World-Space-Koordinaten) in den Projektorraum überführt werden müssen ("viewing transform", vergleichbar mit mit dem Applizieren der MODELVIEWMATRIX bei der Kamera).
Dann werden diese Koordinaten noch in den Clipping-Space des Projektors übersetzt (entspricht der Übersetzung in den Clipping-Space der Kamera mit der PROJECTIONMATRIX)
Zu guter Letzt müssen diese Koordinaten noch auf die Textur gemappt werden.
D.h., dass die "Bildbreite" (des vom Projektor geworfenen "Bildes") und "-höhe" in den Intervall [0,1] übersetzt werden müssen, um daraus die uv-Koordinaten in der Textur ablesen zu können.

Diese Technik kann zur Schattenberechnung genutzt werden. In diesem Fall gibt es keine konkrete Textur, sondern der Schatten eines Objekts wird als Textur gewählt.
Dazu rendert man die Szene zunächst aus der Sicht der Lichtquelle (ähnlich dem Projektor oben).
Aus den z-Koordinaten aller (aus Lichtperspektive sichtbaren) Fragmente kann man eine Tiefenkarte erstellen, welche dann als Textur dient.
Im zweiten Schritt wird die Szene ganz normal aus der Kamerasicht gerendert.
Allerdings wird für jedes (aus Kameraperspektive sichtbares) Fragment ebenfalls seine Koordinaten im Lichtraum ermittelt.
Im Gegensatz zum normalen Projektiven Texturmapping wird nun aber nicht das entspechende Texel ausgelesen.
Vielmehr kann man mit dem Vergleich zwischen dem z-Wert des Fragments und dem Lookup in der "Textur" (der Tiefenkarte) prüfen, wer näher an der Lichtquelle ist: das aktuelle Fragment oder das Fragment, mit dem ürsprünglich die Tiefenkarte erstellt wurde. Sollte zweiteres der Fall sein, so befindet sich das aktuelle Fragment im Schatten und muss andersfarbig gezeichnet werden.

\end{document}

